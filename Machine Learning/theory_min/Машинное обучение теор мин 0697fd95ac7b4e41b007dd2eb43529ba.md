# Машинное обучение: теор. мин

### **Блок 1**

# 1. Сильный искусственный интеллект; слабый искусственный интеллект; анализ данных.

Сильный искусственный интеллект (общий) - искусственный интеллект, способный достичь или превзойти человеческие когнитивные способности. 

Слабый искусственный интеллект (узкий) - искусственный интеллект, который реализует ограниченную часть разума или сосредоточен на одной узкой задаче. По мере решения задач ИИ их выписывают из задач общего ИИ и относят к узкому ИИ.  

Машинное обучение - разработка алгоритмов машинного обучения

Анализ данных - извлечение знаний из данных, в т.ч. с помощью применения алгоритмов машинного обучения

# 2. Обучение с учителем; обучение без учителя; частичное обучение; обучение с подкреплением; активное обучение; онлайн обучение.

Все это - типы задач машинного обучения:

- **обучение с учителем** (supervised learning) - тренировочная выборка содержит верные ответы, которые алгоритм должен научиться предсказывать для новых данных. *Задачи, которые могут решаться этим способом:* классификация, вероятностная классификация, восстановление регрессии.
- **обучение без учителя** (unsupervised learning) - тренировочная выборка не содержит целевых признаков. Алгоритму требуется самому придумать новые признаки Y на основе существующих X. *Задачи, которые могут решаться этим способом:* кластеризация, мягкая кластеризация, извлечение признаков.
- **частичное обучение** (semi-supervised learning) - задача обучения с учителем, в которой только малая часть тренировочных данных содержит целевой признак. *Базовое решение:* не использовать объекты, у которых пропущен целевой признак, не использовать целевой признак для обучения. Размеченные объекты можно использовать для тестирования. Размеченные объекты могут статистически отличаться от неразмеченных.
- **обучение с подкреплением** (reinforcement learning) - агент взаимодействует со средой, сообщая ей действие для текущего состояния. Среда сообщает агенту награду за действие и новое состояние. Задача агента - максимизировать суммарную награду. (Эта задача больше похожа на то, как происходит обучение в реальном мире). Агент — это то, что имеет логику действий и взаимодействует с окружением.
- **активное обучение** (active learning) - Есть доступ к большому числу объектов, но не у всех есть метки. Данные собираются быстро, а размечаются медленно и порционно, скорость обучения моделей происходит быстрее, чем разметка. В активном обучении условия такие же, как в частичном обучении, но можно задавать Оракулу вопросы о значении меток. Требуется восстановить f: X → Y за наименьшее число обращений к Оракулу (найти стратегию обращений к Оракулу, оптимизирующую качество аппроксимации f).
- **онлайн обучение** (online learning) - эти алгоритмы имеют возможность дообучить модель на новых данных.

# 3. Классификация; регрессия; ранжирование; прогнозирование; метод обучения; функция потерь; эмпирический риск; метод минимизации эмпирического риска; гиперпараметры алгоритма.

Классификация - задача обучения с учителем, в которой типом целевого признака Y является категория. Этот признак называется классом, меткой класса, label, типом. 

Наивное решение a(x) = Mode[Y] (чаще всего встретившиеся решение)

Регрессия - задача обучения с учителем, в которой типом целевого признака Y является число. 

Наивное решение a(x) = E[Y]

Прогнозирование:

![Screenshot 2022-10-25 at 22.30.10.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_22.30.10.png)

Ранжирование:

![Screenshot 2022-10-25 at 22.17.03.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_22.17.03.png)

Метод обучения:

![Screenshot 2022-10-25 at 22.32.47.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_22.32.47.png)

Функция потерь - функция, характеризующая величину отклонения ответа от правильного на произвольном объекте.

Эмпирический риск - функционал качества, характеризующий среднюю ошибку алгоритма $а$ на выборке $X^m$

![Screenshot 2022-10-25 at 22.42.55.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_22.42.55.png)

Метод минимизации эмпирического риска заключается в том, чтобы в заданной модели алгоритмов $А$ найти алгоритм, при котором достигается минимальное значение функционала эмпирического риска.
Например найти такие гиперпараметры для алгоритма, чтобы потери (результат применения функции эмпирического риска) были минимальны (т.е. у ответов была минимальная погрешность).

![Screenshot 2022-10-25 at 22.45.15.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_22.45.15.png)

Гиперпараметры алгоритма:

- Параметры алгоритма обучения
- Параметры, которые не меняются во время обучения
    
    ![Screenshot 2022-10-25 at 22.47.03.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_22.47.03.png)
    
    # 4. Переобучение; валидация; кросс-валидация; leave-one-out; регуляризация
    
    **Переобучение** (англ. overfitting) — негативное явление, возникающее, когда алгоритм обучения вырабатывает предсказания, которые слишком близко или точно соответствуют конкретному набору данных и поэтому не подходят для применения алгоритма к дополнительным данным или будущим наблюдениям.
    
    **Валидация** - способ проверки качества обучения нашей модели. Так мы определим что наша модель обучена нормально/переобучена/недообучена. Смысл валидации в том, чтобы выбрать модель, которая лучше всех обучается и меньше всех переобучается на имеющихся данных (или лучше всех обобщает на обучающую выборку). Не в том, чтобы обучить модель без переобучения.
    
    **Кросс-валидация** - процедура эмпирической оценки обобщающей способности алгоритма. С помощью кросс-валидации эмулируется наличие тестовой выборки, которая не участвует в обучении, но для которой известны правильные ответы. 
    
    - **Виды кросс-валидации**:
        - K-fold - алгоритм:
            1. Делим выборку на k примерно равных частей
            2. Цикл по i=1,...k: используем i-ю часть для вычисления ошибки, объединение остальных для обучения.
            3. усредняем полученные k ошибок
        - Leave-one-out - K-fold, где k=количеству наблюдений в выборке
        • LeaveOneGroupOut - алгоритм:
            1. Делим выборку на несколько групп в данных (по значениям фичей или по
            каким-то содержательным соображениям)
            2. Цикл по i=1,...количество выделенных групп: используем i-ю группу для
            вычисления ошибки, а остальные для обучения модели.
            3. Усредняем полученные ошибки (можно усреднять с весами, пропорцио-
            нальными размеру группы в выборке, если есть необходимость)
        - Out-of-time-контроль - кросс-валидация для временных рядов
    
    **leave-one-out** - вид кросс-валидации по отдельным объектам. В тестовой выборке находится один объект, в тренировочной — все остальные. Когда алгоритм обучается не на всех объектах, теряется часть информации. Здесь не теряется. Но это долго.
    
    **Регуляризация** - метод добавления некоторых дополнительных ограничений к условию с целью предотвратить переобучение или повысить вербализуемость моделей. Чаще всего имеет вид штрафа за сложность модели.
    
    Как пример, ограничение вектора шага в градиентном спуске.
    
    - **Виды регуляризации:**
        - [L2-регуляризация](http://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F#.5Bmath.5DL_.7B2.7D.5B.2Fmath.5D-.D1.80.D0.B5.D0.B3.D1.83.D0.BB.D1.8F.D1.80.D0.B8.D0.B7.D0.B0.D1.86.D0.B8.D1.8F)
        - [L1-регуляризация](http://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F#.5Bmath.5DL_.7B1.7D.5B.2Fmath.5D-.D1.80.D0.B5.D0.B3.D1.83.D0.BB.D1.8F.D1.80.D0.B8.D0.B7.D0.B0.D1.86.D0.B8.D1.8F)
        - [Эластичная сеть](http://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F#.D0.AD.D0.BB.D0.B0.D1.81.D1.82.D0.B8.D1.87.D0.BD.D0.B0.D1.8F_.D1.81.D0.B5.D1.82.D1.8C) - сумма двух предыдущих
        - [Гребневая регрессия](http://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F#.D0.93.D1.80.D0.B5.D0.B1.D0.BD.D0.B5.D0.B2.D0.B0.D1.8F_.D1.80.D0.B5.D0.B3.D1.80.D0.B5.D1.81.D1.81.D0.B8.D1.8F)
        - [Лассо регрессия](http://neerc.ifmo.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F#.D0.9B.D0.B0.D1.81.D1.81.D0.BE_.D1.80.D0.B5.D0.B3.D1.80.D0.B5.D1.81.D1.81.D0.B8.D1.8F)
        - и другие
    
    # 5. Точность; полнота; accuracy; F-мера; true positive; false positive; ROC-кривая; среднеквадратическое отклонение
    
    В бинарной классификации можно выделить два класса, пусть будут Positive/Negative.
    В множественной классификации можно например сказать что один из них == Positive, все остальные вместе == Negative.
    
    Верный ответ == алгоритм предсказал верно
    
    ∙ TP (True Positive) — Число верных ответов положительного класса
    ∙ TN (True Negative) — Число верных ответов отрицательного класса
    ∙ FP (False Positive) — Число ошибок первого рода
    ∙ FN (False Negative) — Число ошибок второго рода
    
    ∙ P = TP + FN - число положительных примеров
    
    ∙ N = FP + TN - число отрицательных примеров
    
    Precision (точность) - доля действительно положительных объектов среди тех, кого отнесли к положительным. Формула:  $\frac {TP}{TP+FP}$ 
    
    Recall (Полнота) - доля положительных объектов, которую алгоритм находит. Формула:   $\frac {TP}  {P}$ 
    
    Accuracy (точность) - определяет на сколько хорошо работает классификатор. Формула: $\frac {TP + TN} {P + N}$
    
    F-мера - среднее гармоническое между точностью и полнотой. Формула после преобразований: $\frac {2 \times Precision \times Recall} {Precision + Recall}$. Кроме того, может являться заменой accuracy, если классы несбалансированны. 
    
    ROC-кривая - зависимость TPR (sensitivity - True Positive Rate, равна Recall) от TNR (specificity - True Negative Rate, равна $\frac {TN} {TN+FP}$). То есть ROC-кривая – графическая характеристика качества бинарного классификатора, зависимость доли верных положительных классификаций от доли ложных положительных классификаций при варьировании порога решающего правила.
    Площадь под ROC кривой (AUC — Area Under Curve) — функция качества бинарной классификации.
    
    Среднеквадратичная ошибка (Mean Squared Error) – Среднее арифметическое
    квадратов разностей между предсказанными и реальными значениями Модели Машинного обучения
    
    ![Screenshot 2022-10-25 at 23.34.22.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_23.34.22.png)
    
    n - количество наблюдений
    
    $y_i$ - фактическая координата наблюдения
    
    $y_i$ с крышкой - предсказанная координата наблюдения
    
    Также есть Root Mean Squared Error (RMSE) - корень из MSE
    
    Если уж на то пошло, еще есть MAPE и SMAPE - (Symmetric) Mean Absolute Persentage Error
    
    **НО** у них есть приблемы с [антисимметричностью](https://towardsdatascience.com/choosing-the-correct-error-metric-mape-vs-smape-5328dec53fac)
    
    ![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled.png)
    
    A_t - фактическое значение, F_t - предсказанное значение
    
    ![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%201.png)
    
    # 6. Метод ближайших соседей
    
    **Метод ближайших соседей** — простейший метрический классификатор (Метрический классификатор — алгоритм классификации, основанный на вычислении оценок сходства между объектами.), основанный на оценивании сходства объектов. Классифицируемый объект относится к тому классу, которому принадлежат ближайшие к нему объекты обучающей выборки.
    
    ![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%202.png)
    
    Что еще есть для повышения надежности:
    
    **Метод k ближайших соседей**  — Для повышения надёжности классификации объект относится к тому классу, которому принадлежит большинство из его соседей — k ближайших к нему объектов обучающей выборки x_i (x итый). В задачах с двумя классами число соседей берут нечётным, чтобы не возникало ситуаций неоднозначности, когда одинаковое число соседей принадлежат разным классам.
    
    **Метод взвешенных ближайших соседей** — в задачах с числом классов 3 и более нечётность уже не помогает и ситуации неоднозначности всё равно могут возникать. Тогда i-му соседу приписывается вес w_i (w итый), как правило, убывающий с ростом ранга соседа i. Объект относится к тому классу, который набирает больший суммарный вес среди k ближайших соседей.
    
    # 7. Метод непараметрической регрессии
    
    Непараметрическая регрессия - в окрестности некоторой точки $\theta$(тета) - константа, пользуясь формулой эмперического риска, пытаемся устремить ее (формулу) к минимуму по всем тета. Для этого будем использовать ядерное сглаживание. В формуле ядерного сглаживания присутствует функция ядра k и h - ширина окна, пользуясь формулой Надарая-Ватсона считаем скользящее среднее 
    
    Грубо говоря: Регрессия, которая не описывается конечным числом параметров. 
    
    Непараметрическое название весьма условно, так как гиперпараметры есть, которые можно и нужно настраивать 
    
    ![Screenshot 2022-10-25 at 23.57.01.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_23.57.01.png)
    
    ![Screenshot 2022-10-25 at 23.57.14.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-25_at_23.57.14.png)
    
    # 8. Метод стохастического градиентного спуска
    
    **Стохастический градиентный спуск -** оптимизационный алгоритм, отличающийся от обычного градиентного спуска тем, что градиент оптимизируемой функции считается на каждом шаге не как сумма градиентов от каждого элемента выборки, а как градиент от одного, случайно выбранного элемента. (Чтобы доказать что стохастический метод сходится, используется теорема Новикова)
    
    **Градиентный спуск** — метод нахождения локального минимума или максимума функции с помощью движения вдоль градиента (градиент - вектор, своим направлением указывающий направление возрастания (а антиградиент - убывания) некоторой скалярной величины, значение которой меняется от одной точки пространства к другой, образуя скалярное поле, а по величине (модулю) равный скорости роста этой величины в этом направлении.). Для минимизации функции в направлении градиента используются [методы одномерной оптимизации](https://ru.wikipedia.org/w/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D0%BE%D0%B4%D0%BD%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D0%B9_%D0%BE%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8&action=edit&redlink=1), например, [метод золотого сечения](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B7%D0%BE%D0%BB%D0%BE%D1%82%D0%BE%D0%B3%D0%BE_%D1%81%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D1%8F). Также можно искать не наилучшую точку в направлении градиента, а какую-либо лучше текущей.
    
    Наиболее простой в реализации из всех методов локальной оптимизации. Имеет довольно слабые условия сходимости, но при этом скорость сходимости достаточно мала (линейна). Шаг градиентного метода часто используется как часть других методов оптимизации, например, метод [Флетчера — Ривса](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D1%81%D0%BE%D0%BF%D1%80%D1%8F%D0%B6%D1%91%D0%BD%D0%BD%D1%8B%D1%85_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BE%D0%B2).
    
    # 9. Метод линейной регрессии; гребневая регрессия; лассо Тибширани
    
    **Метод линейной регрессии** - метод восстановления зависимости одной (объясняемой, зависимой) переменной y от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) x с линейной функцией зависимости. Данный метод позволяет предсказывать значения зависимой переменной y по значениям независимой переменной x.
    
    **Гребневая регрессия** или **ридж-регрессия** — один из методов [понижения размерности](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A3%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B5%D0%BD%D0%B8%D0%B5_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%BE%D1%81%D1%82%D0%B8). Применяется для борьбы с избыточностью данных, когда независимые переменные коррелируют друг с другом, вследствие чего проявляется неустойчивость оценок коэффициентов многомерной линейной регрессии. (у значений вектора распределение гаусса)
    
    Метод стоит использовать, если:
    
    - сильная обусловленность;
    - сильно различаются собственные значения или некоторые из них близки к нулю;
    - в матрице X есть почти линейно зависимые столбцы.
    
    **Метод регрессии лассо** - похож на гребневую регрессию, но он использует другое ограничение на коэффициенты (у значений вектора распределение лапласа)
    
    Основное различие лассо- и ридж-регрессии заключается в том, что первая может приводить к обращению некоторых независимых переменных в ноль, тогда как вторая уменьшает их до значений, близких к нулю.
    
    # 10. Метод сингулярного векторного разложения
    
    Теорема: Любая матрица F размера |D| × n может быть представлена в виде **сингулярного разложения**:
    
    ![Screenshot 2022-10-05 at 02.09.24.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-05_at_02.09.24.png)
    
    Представим какое-то скрытое пространство, в которое мы хотим проецировать данные (матрицу F ). Это пространство можно описать базисными векторами. D представляет важность каждого базисного вектора, V представляет, как объекты соответствуют базисным векторам, U показывает, как признаки соответствуют
    базисным векторам.
    
    С помощью этого метода можно ускорить классический метод наименьших квадратов. Кроме того, **сингулярное разложение** — важный инструмент во многих других задачах машинного обучения, в первую очередь, в снижении размерности.
    
    # 11. Метод опорных векторов
    
    Метод опорных векторов - линейный алгоритм 
    
    Основная идея заключается в построении гиперплоскости, разделяющей объекты выборки оптимальным способом. Алгоритм работает в предположении, что чем больше расстояние (зазор) между разделяющей гиперплоскостью и объектами разделяемых классов, тем меньше будет средняя ошибка классификатора.
    
    Преимущества SVM перед методом стохастического градиента и нейронными сетями:
    
    - Задача выпуклого квадратичного программирования хорошо изучена и имеет единственное решение.
    - Метод опорных векторов эквивалентен двухслойной нейронной сети, где число нейронов на скрытом слое определяется автоматически как число опорных векторов.
    - Принцип оптимальной разделяющей гиперплоскости приводит к максимизации ширины разделяющей полосы, а следовательно, к более уверенной классификации.
    
    Недостатки классического SVM:
    
    - Неустойчивость к шуму: выбросы в исходных данных становятся опорными объектами-нарушителями и напрямую влияют на построение разделяющей гиперплоскости.
    - Не описаны общие методы построения ядер и спрямляющих пространств, наиболее подходящих для конкретной задачи.
    - Нет отбора признаков.
    - Необходимо подбирать константу С при помощи кросс-валидации

# 12. Ядро; ядерный трюк для метода опорных векторов

**Ядро - это непрерывная ограниченная симметричная вещественная функция с единичным интегралом, представляемая в виде скалярного произведения.** 

**Ядро** содержит в себе много информации о спрямляющем пространстве, и позволяет производить в нем различные операции, не зная самого отображения ϕ(x).

**Ядерный трюк -** метод в машинном обучении, позволяющий перевести элементы для случая линейной неразделимости в спрямляющее (т.е. линейно разделимое) пространство. Поскольку для любой непротиворечивой выборки соответствующее пространство большей размерности существует, главной проблемой становится его найти.

Основная идея: 

- найти неявное отображение в многомерное пространство, такое, что точки в новом пространстве будут линейно разделимы.
- вычислять ядро быстрее, чем скалярное произведение с явным преобразованием.

Пример: На первой картинке справа можно увидеть, что 2 класса неразделимы линейно, но после преобразования появляется разделяющая плоскость.

![Screenshot 2022-10-05 at 02.20.46.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-05_at_02.20.46.png)

# 13. Вероятностная постановка задачи классификации; правдоподобие класса; метод максимальной апостериорной вероятности; оптимальный байесовский классификатор

Вероятностная постановка задачи классификации:

![Screenshot 2022-10-26 at 00.32.28.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_00.32.28.png)

Разница с остальным: восстанавливаем именно плотность распределения, а не функцию x → Y

Почему классификация вероятностная: потому что объект может принадлежать и одному, и другому классу, при том что описание этого объекта одинаковое, то есть вектор признаков, который описывает объект одинаковый, но при этом объект может принадлежать разным классам, поэтому мы и хотим восстановить области распределения, чтоб понимать куда отнести тот или иной объект. 

Правдоподобие класса:

p(X, Y) = p(x) Pr(y|x) = Pr(y) p(x|y)              p - правдоподобие, pr - вероятность

Pr(y) — априорная вероятность класса y: какова вероятность того, что мы можем встретить в выборке объект класса y
p(x|y) — правдоподобие (likelihood) класса y (плотности распределения называются функциями правдоподобия классов)
Pr(y|x) — апостериорная вероятность класса y: насколько вероятно, что у х будет класс y. С точки зрения задачи классификации это то, что мы и будем пытаться найти, чтоб найти плотность. 

Метод максимальной апостериорной вероятности. Основная идея: для нового объекта будем возвращать класс, к которому он принадлежит с наибольшей вероятностью. Принцип выражается через оценку апостериорного максимума: нужно найти такой y, при значении которого Pr(y|x) (апостериорная вероятность) будет максимальна 

![Screenshot 2022-10-26 at 01.03.38.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_01.03.38.png)

Оптимальный байесовский классификатор - формула такая же как при оценки апостериорного максимума, но добавляется штраф на каждый класс. 

![Screenshot 2022-10-26 at 01.03.53.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_01.03.53.png)

То есть величина штрафа для ошибки первого рода должна быть больше, чем для величины штрафа для ошибки второго рода 

![Screenshot 2022-10-26 at 01.07.20.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_01.07.20.png)

где $R(a_{ов})$ - средний риск

# 14. Метод оценки Парзена-Розенблатта; наивный байесовский классификатор

**Метод оценки Парзена-Розенблатта -** Алгоритм классификации, в основе которого лежит вероятностная оценка плотности Парзена-Розенблатта. Можно оценить плотность распределения для каждого класса, а затем найти плотность объекта для каждого класса и взять наибольшую**.** Используется в методе kNN для задания весовой функции.

Алгоритм kNN можно обобщить с помощью функции ядра , с помощью фиксированной и переменной ширины окна. 

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%203.png)

Классификатор фиксированной ширины не будет учитывать соседей на расстояние больше чем h, а всех остальных учтет в соответствии с функций ядра K.

Классификатор переменной ширины является аналогом метода k ближайших соседей (т.к. для всех k+i - ых соседей функция K вернет 0), но при этом чем ближе k−i - ый сосед, тем больший вклад в сторону своего класса он даст.

Чаще используют Классификатор переменной ширины, потому что удобнее оптимизировать целочисленный параметр k, чем вещественный параметр h по некоторой сетке. Плюс существует большое количество задач, где точки разбросаны неравномерно, тогда Классификатор фиксированной ширины ломается, не захватывая в некоторые области ни одного объекта.

**Наивный байесовский классификатор -** алгоритм, который делает предположение, что все переменные в наборе данных "наивные", т.е. не коррелируют друг с другом. Он своей основе использует Теорему Байеса, которая позволяет рассчитать [апостериорную вероятность](https://ru.wikipedia.org/wiki/%D0%90%D0%BF%D0%BE%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%BE%D1%80%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C) P(A | B) на основе P(A), P(B) и P(B | A). В основном используется для получения базовой точности набора данных.

**Плюсы**

- Алгоритм легко и быстро предсказывает класс тестового набора данных. Он также хорошо справляется с многоклассовым прогнозированием.
- Производительность наивного байесовского классификатора лучше, чем у других простых алгоритмов, таких как логистическая регрессия. Более того, вам требуется меньше обучающих данных.
- Он хорошо работает с категориальными признаками(по сравнению с числовыми). Для числовых признаков предполагается нормальное распределение, что может быть серьезным допущением в точности нашего алгоритма.

**Минусы**

- Если переменная имеет категорию (в тестовом наборе данных), которая не наблюдалась в обучающем наборе данных, то модель присвоит 0 (нулевую) вероятность и не сможет сделать предсказание. Это часто называют нулевой частотой. Чтобы решить эту проблему, мы можем использовать технику сглаживания. Один из самых простых методов сглаживания называется [оценкой Лапласа](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%9B%D0%B0%D0%BF%D0%BB%D0%B0%D1%81%D0%B0).
- Значения спрогнозированных вероятностей, возвращенные методом *predict_proba*, не всегда являются достаточно точными.
- Ограничением данного алгоритма является предположение о независимости признаков. Однако в реальных задачах полностью независимые признаки встречаются крайне редко.

# 15. Задача параметрической оценки плотности; принцип максимального правдоподобия

Задача параметрической оценки плотности: задача восстановления плотности распределения, основанная на предположении о том, что плотность p(x) известна с точностью до параметра $\theta$, и является фиксированной функцией $\phi$(x, $\theta$). Параметр theta можно оценить по выборке с использованием принципа максимального правдоподобия.

В чем смысл: нам надо найти такие тета, при которых функция правдоподобия достигает максимума.  

Производная равна нулю: такие вещи (оптимум) ищутся при помощи градиентного спуска 

![Screenshot 2022-10-26 at 01.18.48.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_01.18.48.png)

Принцип совместного максимального правдоподобия:

Пытаемся построить распределение параметров нашего распределения, которое мы хотим найти. 

![Screenshot 2022-10-26 at 01.26.53.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_01.26.53.png)

# 16. Метод логистической регрессии; сигмоида

**Метод логистической регрессии** - Это алгоритм для решения задачи бинарной классификации (бинарная классификация — это частный случай классификации, когда классов всего два: `"0"` или `"1"`. Говорят, что целевая переменная здесь — **бинарная величина**). 

Модели, обученные алгоритмами для бинарной классификации, могут не просто прогнозировать финальное значение класса для какого-то объекта или клиента, а ещё и оценивать вероятность рассматриваемого события. Например:

- вероятность возврата кредита клиентом;
- вероятность возникновения страхового случая;

Алгоритмом для решения таких задач будет логистическая регрессия.

График логистической функции называют **сигмоида**. По нему видно, что логистическая функция принимает значения от 0 до 1. Внешний вид и область допустимых значений сигмоиды хорошо подходит для представления вероятности наступления какого-то события. Эта кривая «загибается» на бесконечно маленьких и бесконечно больших значениях `z`.

![Screenshot 2022-10-05 at 02.30.35.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-05_at_02.30.35.png)

# 18. Дерево принятия решений; подрезка

**Деревья** выбирают ответ сценарным подходом, в отличии от классификации, которая представляет значение целевой функции — как сумму взвешенных значений признаков (линейной функции).

Последовательностью признаков алгоритм пытается так разбить выборку, чтобы группы в конце дерева (в листьях) были максимально отделимы на основании наблюдаемых данных.

Чем деревья хороши:

- Они легко интерпретируемы. В бизнесе это часто становится ключевым. Более сложные алгоритмы напоминают «чёрный ящик» и неясно, по какому именно принципу они принимают решения.
- Годятся и для классификации, и для регрессии — в этом случае в листьях дерева будут числа, а не значение класса.
- Достаточно быстры.
- Не требуют серьёзной предобработки данных: деревья не чувствительны к масштабу признаков и устойчивы к их мультиколлинеарности.

Чем деревья плохи:

- Они сильно переобучаются. Это значит, что модель слишком сильно подгонит параметры или разбиение веток под обучающую выборку. На *train* она будет работать очень хорошо, а вот на новых данных нет. Иногда при большом количестве признаков вы можете строить ветку так, что в листе будет один объект, или совсем немного. По сути дерево подстроится под конкретную обучающую выборку, пытаясь оставить в листе объекты лишь одного класса.
- Только верхние вершины влияют на качество алгоритма.

Чтобы избежать переобучения, проводят процедуру «обрезки» дерева — **prunning - обработка созданных деревьев, когда последовательно применяются операторы упрощения, если они улушают качество по определенному критерию.**
Она заключается в том, чтобы в определённый момент обрезать ветку, не позволяя дереву переобучаться. Эффект переобучения особенно заметен на небольших выборках.

Дерево решений - алгоритм классификации и регрессии. Вершины содержат разделяющие правила (вопросы). Ребро - возможный ответ на вопрос в родительской вершине. Листья содержат решения (класс объекта для задачи классификации и число для задачи регрессии).

Алгоритм примерно такой:

1. Разбить выборку в отношении 2 к 1 на тренировочную и тестовую (валидационную).
2. Для каждой вершины применяем определенный оператор упрощения, который является лучшим с точки зрения выбранного критерия качества:
    - ничего не менять
    - заменить вершину ребенком (для каждого ребенка)
    - заменить вершину листом (для каждого класса)

# 19. Бустинг алгоритмов; метод градиентного бустинга

Бустинг (англ. boosting — улучшение) — это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов. На каждом шаге новая модель обучается с использованием данных об ошибках предыдущих.

Одним из недостатков бустинга является то, что он может приводить к построению громоздких композиций, состоящих из сотен алгоритмов. Такие композиции исключают возможность содержательной интерпретации, требуют больших объёмов памяти для хранения базовых алгоритмов и существенных затрат времени на вычисление классификаций.

Градиентный бустинг - продвинутый алгоритм машинного обучения для решения задач классификации и регрессии. Он строит предсказание в виде ансамбля слабых предсказывающих моделей, которыми в основном являются деревья решений. Из нескольких слабых моделей собираем одну эффективную. Общая идея: последовательное применение предиктора таким образом, что каждая следующая модель сводит ошибку предыдущей к минимуму. 

# 20. Метод AdaBoost

Один из алгоритмов классификации, в процессе обучения строит композицию из базовых алгоритмов обучения для улучшения их эффективности, каждый следующий классификатор **строится (в основном) по объектам, которые плохо классифицируются предыдущими классификаторами.** 
То есть мы больше штрафуем алгоритм за ошибки на объектах с большими весами

---

Алгоритм может использоваться в сочетании с несколькими алгоритмами классификации для улучшения их эффективности. Алгоритм усиливает классификаторы, объединяя их в «комитет». AdaBoost является адаптивным в том смысле, что каждый следующий комитет классификаторов строится по объектам, неверно классифицированным предыдущими комитетами. AdaBoost чувствителен к шуму в данных и выбросам. Однако он менее подвержен переобучению по сравнению с другими алгоритмами машинного обучения.

AdaBoost вызывает слабые классификаторы. После каждого вызова обновляется распределение весов, которые отвечают важности каждого из объектов обучающего множества для классификации. На каждой итерации веса каждого неверно классифицированного объекта возрастают, таким образом новый комитет классификаторов «фокусирует своё внимание» на этих объектах.

Комитет = ансамбль — серьёзные модели машинного обучения. Они мощные и позволяют отражать сложные зависимости между данными. Однако за «силу» ансамблей приходится платить их интерпретируемостью.

Такие алгоритмы часто называют **«чёрными ящиками»**: по ним трудно понять, какие же признаки повлияли на прогноз для конкретного наблюдения.

# 21. Бутстрап; случайный лес; стэкинг

Бутстреп - подход, при котором оценивают различные характеристики или прогнозы на основании множества различных подвыборок из исходной. Используется для бэггинга (усреднение моделей, обученных на разных подвыборках). Основан на многократной генерации выборок на базе уже имеющейся. Используется в алгоритме "Случайный лес”.

Случайный лес - алгоритм, в основе которого лежит бэггинг. Учим деревья решений на случайно выбранной части данных (обычно $\sqrt{n}$, n - число признаков), а затем усредняем их результаты.

Стэкинг - ансамблевый метод машинного обучения, который на части тренировочных данных обучает базовые модели, а затем обучает метамодель на основе предсказаний базовых моделей на оставшейся части тренировочной выборки.

### Блок 2

# 22. Нейрон; перцептрон;

Нейрон - клетка, имеющая множество отростков (дендритов), накапливает сигналы от дендритов, возбуждается и передает сигнал дальше. Один из дендритов (аксон) как раз и передает этот сигнал дальше.

Перцептрон - простейший вид нейронных сетей. В основе лежит математическая модель восприятия информации мозгом, состоящая из сенсоров, ассоциативных и реагирующих элементов. Таким образом, перцептроны позволяют создать набор “ассоциаций” между входными стимулами и необходимой реакцией на выходе.

 

Перцептрон это input values, weights, sum, actuvation function (все элементы вместе - модель нейрона)

Функция активации определяет выходное значение перцептрона и применяется после его вычисления. Например, tanh или сигмоида.

# 23. Многослойная нейронная сеть; автоматическое дифференцирование

Многослойная нейронная сеть - по сути это матричные вычисления. На входе у нас есть набор нейронов (скалярных произведений), каждый слой это множество скалярных произведений, т.е. произведение матриц. Таким образом можно представить нашу структуру так: получает на вход вектор, его умножает на матрицу, с полученным вектором производит сдвиг и другие операции и идёт дальше: Input → * M1 + b1 → * M2 → f() → Output .

Если мы будет выстраивать из искусственных нейронов сеть, которая будет состоять из слоев, то так как нейрон по сути - скалярное произведение, а множество скалярных произведений - умножение на матрицу, тогда нашу послойную архитектуру можно выписать, как функцию, которая поочередно умножает текущий вектор на какую то матрицу, дальше прибавляет к полученному вектору какой то вектор сдвига, дальше применяет к этому какую то не линейную функцию. 

Полученная функция выглядит в виде дерева. 

**Автоматическое дифференцирование** – метод обучения нейросетей, основанный на двух шагах:

1. Прямое распространение (forward propagation) – процесс пропуска входных данных через нейросеть, попутно сохраняя промежуточные ответы и значение функции ошибки;
2. Обратное распространение (backward propagation) – процесс подсчёта градиентов с помощью chain rule.
Благодаря автоматическому дифференцированию можно обучать нейросети любой сложности, так как функции будут раскладываться в элементарные с помощью chain rule. Более того, мы не будем делать подсчёт лишних операций, так как градиенты с верхних слоёв будут сохраняться и утилизироваться далее.

# 25. Аугментация данных; дропаут; ReLU

Аргументация данных - техники генерации данных с помощью добавления копий уже существующих с небольшими изменениями (или генерации на основе существующих данных), то есть это методика создания дополнительных данных из имеющихся данных. Чаще всего, проблема ограниченного набора данных возникает при решении задач, связанных с обработкой изображений. 

Дропаут: 

![Screenshot 2022-10-26 at 03.34.57.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_03.34.57.png)

Делается для избежания переобучения. 

ReLU

**Rectified Linear Unit — это наиболее часто используемая функция активации при глубоком обучении.** Данная функция возвращает 0, если принимает отрицательный аргумент, в случае же положительного аргумента, функция возвращает само число. То есть она может быть записана как f(z)=max(0,z). На первый взгляд может показаться, что она линейна и имеет те же проблемы что и линейная функция, но это не так и ее можно использовать в нейронных сетях с множеством слоев. Функция ReLU обладает несколькими преимущества перед сигмоидой и гиперболическим тангенсом:

1. Очень быстро и просто считается производная. Для отрицательных значений — 0, для положительных — 1.
2. Разреженность активации. В сетях с очень большим количеством нейронов использование сигмоидной функции или гиперболического тангенса в качестве активационный функции влечет активацию почти всех нейронов, что может сказаться на производительности обучения модели. Если же использовать ReLU, то количество включаемых нейронов станет меньше, в силу характеристик функции, и сама сеть станет легче.

У данной функции есть один недостаток, называющийся проблемой умирающего ReLU. Так как часть производной функции равна нулю, то и градиент для нее будет нулевым, а то это значит, что веса не будут изменяться во время спуска и нейронная сеть перестанет обучаться.

Функцию активации ReLU следует использовать, если нет особых требований для выходного значения нейрона, вроде неограниченной области определения. Но если после обучения модели результаты получились не оптимальные, то стоит перейти к другим функциям, которые могут дать лучший результат.

# 26. Метод Ньютона-Рафсона

Основная идея состоит в последовательных приближениях к истинному решению уравнения f(x)=0, которые вычисляются с помощью производной от f(x).

- Вводится нулевая итерация x0.
- В этой точке методом конечных разностей вычисляется производная f’(x).
- Пользуясь разложением тейлора, f(x) заменяется в окрестности точки касательной - прямой линией  f(x0)+f’(x0)(x-x0).
- Определяется точка, в которой прямая пересекает ось X.
- Эта точка принимается за новую итерацию и цикл повторяется, пока корень не будет найден с нужной точностью.

# 27. Декорреляция; метод Xavier; метод He

**Декорреляция** - Процесс, который используется для уменьшения корреляции.

1. Есть матрица X.

2. Матрицу центрировали ($E[X_j]=0$).

3. Ковариация вычисляется по следующей формуле:

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%204.png)

4. Если же матрица нормализована так, что $D[X_j]=1$, то из произведения мы получим не ковариационную, а корреляционную матрицу

5. Декорреляция вычисляется по формуле:

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%205.png)

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%206.png)

**Метод Xavier** - Метод инициализации сети. Основная идея этого метода — упростить прохождение сигнала через слой во время как прямого, так и обратного распространения ошибки для линейной функции активации (этот метод также хорошо работает для сигмоидной функции, так как участок, где она ненасыщена, также имеет линейный характер). При вычислении параметров этот метод опирается на вероятностное распределение (равномерное или нормальное) с дисперсией, равной

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%207.png)

**Метод Ге (He)** — вариация метода Завьера, больше подходящая функции активации ReLU, компенсирующая тот факт, что эта функция возвращает нуль для половины области определения. А именно, в этом случае

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%208.png)

**Инициализация — это процесс установки настраиваемых параметров для нашей глубокой сети. Выбор правильного метода инициализации важен для качества обучения нашей модели. Также это позволяет сократить время сходимости и минимизировать функцию потерь. Поэтому важно уметь выбрать правильный метод инициализации.**

Принцип выбора начальных значений параметров для слоев, составляющих модель очень важен: установка всех параметров в 0 будет серьезным препятствием для обучения, так как ни один из параметров изначально не будет активен. Присваивать параметрам значения из интервала [−1,1] — тоже обычно не лучший вариант — на самом деле, иногда (в зависимости от задачи и сложности модели) от правильной [инициализации сети](https://neerc.ifmo.ru/wiki/index.php?title=%D0%98%D0%BD%D0%B8%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2_%D0%B3%D0%BB%D1%83%D0%B1%D0%BE%D0%BA%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8) может зависеть, достигнет она высочайшей производительности или вообще не будет сходиться. Даже если задача не предполагает такой крайности, удачно выбранный способ инициализации начальных параметров может значительно влиять на способность модели к обучению, так как он предустанавливает параметры модели с учетом функции потерь.

# 30. Метод Adam

Adam - один из самых эффективных алгоритмов оптимизации в обучении нейронных сетей. Он сочетает в себе идеи RMSProp и оптимизатора импульса. Вместого того чтобы адаптировать скорость обучения параметров на основе среднего первого момента (среднего значения), как в RMSProp, Adam также использует среднее значение вторых моментов градиентов. В частности, алгоритм вычисляет экспоненциальное скользящее среднее градиента и квадратичный градиент, а параметры beta1 и beta2 управляют скоростью затухания этих скользящих средних.

Преимущества:

- простая реализация
- вычислительная эффективность
- небольшие требования к памяти
- инвариант к диагональному масштабированию градиентов
- хорошо подходит для нестационарных целей
- подходит для задач с очень шумными или разреженными градиентами
- гиперпараметры имеют наглядную интерпретацию и обычно требуют небольшой настройки

# 31. Метод батчевой нормализации

**Пакетная нормализация** (англ. batch-normalization) — метод, который позволяет повысить производительность и стабилизировать работу [искусственных нейронных сетей](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9D%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8,_%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD). Суть данного метода заключается в том, что некоторым слоям нейронной сети на вход подаются данные, предварительно обработанные и имеющие нулевое [математическое ожидание](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BE%D0%B6%D0%B8%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B9_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D1%8B) и единичную [дисперсию](https://neerc.ifmo.ru/wiki/index.php?title=%D0%94%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D1%8F_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B9_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D1%8B).

## Идея

Нормализация входного слоя нейронной сети обычно выполняется путем масштабирования данных, подаваемых в функции активации. Например, когда есть признаки со значениями от 0 до 1 и некоторые признаки со значениями от 1 до 1000, то их необходимо нормализовать, чтобы ускорить обучение. Нормализацию данных можно выполнить и в скрытых слоях нейронных сетей, что и делает метод пакетной нормализации.

### **Пакет**

**Пакет** (англ. batch). Возможны два подхода к реализации алгоритма градиентного спуска для обучения нейросетевых моделей: стохастический и пакетный.

- [Стохастический градиентный спуск](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA) (англ. stochastic gradient descent) — реализация, в которой на каждой итерации алгоритма из обучающей выборки каким-то (случайным) образом выбирается только один объект;
- Пакетный (батч) (англ. batch gradient descent) — реализация градиентного спуска, когда на каждой итерации обучающая выборка просматривается целиком, и только после этого изменяются веса модели.

Также существует "золотая середина" между стохастическим градиентным спуском и пакетным градиентным спуском — когда просматривается только некоторое подмножество обучающей выборки фиксированного размера (англ. batch-size). В таком случае такие подмножества принято называть мини-пакетом (англ. mini-batch). Здесь и далее, мини-пакеты будем также называть пакетом.

### **Ковариантный сдвиг**

Пакетная нормализация уменьшает величину, на которую смещаются значения узлов в скрытых слоях (т.н. **[ковариантный](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9A%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D1%8F_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD) сдвиг** (англ. covariance shift)).

Ковариантный сдвиг — это ситуация, когда распределения значений признаков в обучающей и тестовой выборке имеют разные параметры (математическое ожидание, дисперсия и т.д.). Ковариантность в данном случае относится к значениям признаков.

Простой способ решить проблему ковариантного сдвига для входного слоя — это случайным образом перемешать данные перед созданием пакетов. Но для скрытых слоев нейронной сети такой метод не подходит, так как распределение входных данных для каждого узла скрытых слоев изменяется каждый раз, когда происходит обновление параметров в предыдущем слое. Эта проблема называется **внутренним ковариантным сдвигом** (англ. internal covariate shift). Для решения данной проблемы часто приходится использовать низкий [темп обучения](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D1%82%D0%BE%D1%85%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9_%D1%81%D0%BF%D1%83%D1%81%D0%BA) (англ. learning rate) и методы [регуляризации](http://en.wikipedia.org/wiki/ru:%D0%A0%D0%B5%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)) при обучении модели. Другим способом устранения внутреннего ковариантного сдвига является метод пакетной нормализации.

### **Свойства пакетной нормализации**

Кроме того, использование пакетной нормализации обладает еще несколькими дополнительными полезными свойствами:

- достигается более быстрая сходимость моделей, несмотря на выполнение дополнительных вычислений;
- пакетная нормализация позволяет каждому слою сети обучаться более независимо от других слоев;
- становится возможным использование более высокого темпа обучения, так как пакетная нормализация гарантирует, что выходы узлов нейронной сети не будут иметь слишком больших или малых значений;
- пакетная нормализация в каком-то смысле также является механизмом регуляризации: данный метод привносит в выходы узлов скрытых слоев некоторый шум, аналогично методу [dropout](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B8_%D1%80%D0%B5%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D1%85_%D1%81%D0%B5%D1%82%D0%B5%D0%B9#Dropout);
- модели становятся менее чувствительны к начальной инициализации весов.

# 32. Свертка; паддинг; пулинг; страйд; тензор

**Свертка** — операция над парой матриц A (размера $n_x×n_y$) и B(размера $m_x×m_y$), результатом которой является матрица C=$A\times{B}$ размера ($n_x−m_x+1$)×($n_y−m_y+1$). Каждый элемент результата вычисляется как скалярное произведение матрицы B и некоторой подматрицы A такого же размера (подматрица определяется положением элемента в результате). Получившееся число записывается в соответствующий элемент результата.

**Логический смысл свертки такой** — чем больше величина элемента свертки, тем больше эта часть матрицы A была похожа на матрицу B (похожа в смысле скалярного произведения). Поэтому матрицу A называют *изображением*, а матрицу B — *фильтром* или *образцом*.

Можно заметить, что применение операции свертки уменьшает изображение. Также пиксели, которые находятся на границе изображения участвуют в меньшем количестве сверток, чем внутренние. В связи с этим в сверточных слоях используется **дополнение изображения** (англ. ***padding***). Выходы с предыдущего слоя дополняются пикселями так, чтобы после свертки сохранился размер изображения. Такие свертки называют *одинаковыми* (англ. *same convolution*), а свертки без дополнения изображения называются *правильными* (англ. *valid convolution*). Среди способов, которыми можно заполнить новые пиксели, можно выделить следующие:

- *zero shift*: `00[ABC]00`;
- *border extension*: `AA[ABC]CC`;
- *mirror shift*: `BA[ABC]CB`;
- *cyclic shift*: `BC[ABC]AB`.

Еще одним параметром сверточного слоя является ***сдвиг*** (англ. ***stride***). Хоть обычно свертка применяется подряд для каждого пикселя, иногда используется сдвиг, отличный от единицы — скалярное произведение считается не со всеми возможными положениями ядра, а только с положениями, кратными некоторому сдвигу s. Тогда, если если вход имел размерность $w×h$, а ядро свертки имело размерность $k_x×k_y$ и использовался сдвиг s, то выход будет иметь размерность

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%209.png)

**Пулинговый слой** призван снижать размерность изображения. Исходное изображение делится на блоки размером $w×h$ и для каждого блока вычисляется некоторая функция. Чаще всего используется функция максимума (англ. *max pooling*) или (взвешенного) среднего (англ. *weighted) average pooling*). Обучаемых параметров у этого слоя нет. Основные цели пулингового слоя:

- уменьшение изображения, чтобы последующие свертки оперировали над большей областью исходного изображения;
- увеличение инвариантности выхода сети по отношению к малому переносу входа;
- ускорение вычислений.

**Тензор** **— это обобщение векторов и матриц на более высокие измерения. Это объект линейной алгебры, линейно преобразующий элементы одного линейного пространства в элементы другого. Через тензор (который, по сути, трехмерная матрица) можно задать цветное изображение с размерностью: ширина, высота, глубина (она кодирует цвет). Матрицу можно превратить в вектор признаков наивным образом, но тогда потеряются важные инварианты изображения. 

# 33. Сверточная нейронная сеть

Сверточная нейронная сеть - специальная архитектура нейронных сетей, предложенная Яном Лекумом, изначально нацеленная на эффективное распознавание изображений. В сверточной нейронной сети выходы промежуточных слоев образуют матрицу (изображение) или набор матриц (несколько слоев изображения). Так, например, на вход сверточной сети можно подавать три слоя изображения (R-, G-, B-каналы изображения). Основными видами слоев в сверточной нейронной сети являются, пулинговые слои и полносвязные слои.

# 34. Задача семантической сегментации; задача детекции объектов

Задача семантической сегментации - задача, в которой на вход модели подается изображение, а на выходе для каждого пикселя является метка принадлежности этого пикселя к определенной категории.

Задача детекции объектов - задача, в рамках которой необходимо выделить несколько объектов на изображении посредством нахождения координат их ограничивающих рамок и классификации этих ограничивающих рамок из множества заранее известных классов. Число объектов, которые находятся на изображении, заранее неизвестно.

# 35. Рекуррентная нейронная сеть

Рекуррентная нейронная сеть - вид нейронных сетей, где связи между элементами образуют направленную последовательность. Благодаря этому появляется возможность обрабатывать серии событий во времени или последовательные пространственные цепочки. В отличие от многослойных перцептронов, рекуррентные сети могут использовать свою внутреннюю память для обработки последовательностей произвольной длины. Поэтому эти сети применимы в таких задачах, где нечто целостное разбито на части, например: распознавание речи, генерация описания изображений.

# 36. Модуль памяти в рекуррентных сетях

Рекуррентные нейронные сети добавляют память к искусcтвенным нейронным сетям, но реализуемая память получается короткой — на каждом шаге обучения информация в памяти смешивается с новой и через несколько итераций полностью перезаписывается.

Эти модули разработаны специально, чтобы избежать проблемы долговременной зависимости, запоминая значения как на короткие, так и на длинные промежутки времени. Это объясняется тем, что LSTM-модуль не использует функцию активации внутри своих рекуррентных компонентов. Таким образом, хранимое значение не размывается во времени и градиент не исчезает при использовании метода обратного распространения ошибки во времени при тренировке сети.

Ключевые компоненты модуля памяти: состояние ячейки и различные фильтры. О состоянии ячейки можно говорить, как о памяти сети, которая передает соответствующую информацию по всей цепочке модулей. Таким образом, даже информация из ранних временных шагов может быть получена на более поздних, нивелируя эффект кратковременной памяти.

По мере того, как происходит обучение, состояние ячейки изменяется, информация добавляется или удаляется из состояния ячейки структурами, называемыми фильтрами. Фильтры контролируют поток информации на входах и на выходах модуля на основании некоторых условий. Они состоят из слоя сигмоидальной нейронной сети и операции поточечного умножения.

Сигмоидальный слой возвращает числа в диапазоне [0; 1], которые обозначают, какую долю каждого блока информации следует пропустить дальше по сети. Умножение на это значение используется для пропуска или запрета потока информации внутрь и наружу памяти. Например, входной фильтр контролирует меру вхождения нового значения в память, а фильтр забывания контролирует меру сохранения значения в памяти. Выходной фильтр контролирует меру того, в какой степени значение, находящееся в памяти, используется при расчёте выходной функции активации.

# 37. Двунаправленная рекуррентная сеть; Seq-2-Seq сеть

**Двунаправленная рекуррентная сеть** (англ. Bidirectional Recurrent Neural Network, biRNN) представляет собой две однонаправленные рекуррентные сети, одна из которых обрабатывает входную последовательность в прямом порядке, а другая — в обратном. Таким образом, для каждого элемента входной последовательности считается два вектора скрытых состояний, на основе которых вычисляется выход сети. Благодаря данной архитектуре сети доступна информация о контексте как из прошлого, так и из будущего, что решает проблему однонаправленных рекуррентных сетей. Для обучения biRNN используются те же алгоритмы, что и для RNN.

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2010.png)

**Seq-2-seq** (Sequence to sequence, Seq2seq) сеть является базовой архитектурой many-to-many RNN и используется для трансляции одной последовательности в другую. Она состоит из двух рекуррентных сетей: кодировщика и декодировщика. Кодировщик вычисляет вектор, кодирующий входную последовательность. Далее данный вектор передается декодировщику, который в свою очередь по полученному скрытому представлению восстанавливает целевую последовательность. При этом каждый посчитанный выход используется для обновления скрытого представления.

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2011.png)

# 38. Механизм внимания в рекуррентных сетях

Механизм внимания в рекуррентных сетях - это техника для поиска взаимосвязей между различными частями входных и выходных данных. Изначально механизм внимания был представлен в контексте рекуррентных Seq2Seq сетей для “обращения внимания” блоков декодеров на скрытые состояния RNN для любой итерации энкодера, а не только последней. Несмотря на то, что LSTM и GRU блоки в Seq2Seq сетях используются именно для улучшения передачи информации с предыдущих итераций RNN их основная проблема заключается в том, что влияние предыдущих состояний на текущее уменьшается экспоненциально от расстояния между словами, в то же время механизм внимания улучшает этот показатель до линейного.

# 39. Векторные представления слов; Word2Vec; skip-gram; CBOW

Векторные представления слов - общее название для различных подходов к моделированию языка и обучению представлений в обработке естественного языка, направленных на сопоставление словам из некоторого словаря векторов небольшой размерности.

Word2Vec - способ построения сжатого пространства векторов слов, использующий нейронные сети. Принимает на вход большой текстовый корпус и сопоставляет каждому слову вектор. Сначала он создает словарь, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, имеющие схожий смысл), в векторном представлении имеют высокое косинусное сходство. В word2vec существуют две основных модели обучения: skip-gram и CBOW. 

В модели *Skip-gram* по слову предсказываются слова из его контекста, а в модели *CBOW*
 по контексту подбирается наиболее вероятное слово.

В обеих моделях входные и выходные слова подаются в one-hot encoding

## One-hot encoding

Пусть число различных слов равно K. Сопоставим слову с номером i вектор длины K, в котором i-тая координата равна единице, а все остальные — нулям. Недостатком one-hot encoding является то, что по векторным представлениям нельзя судить о схожести смысла слов. Также вектора имеют очень большой размер, из-за чего их неэффективно хранить в памяти.

### Блок 3

# 40. Задача кластеризации; внешние меры оценки; внутренние меры оценки

Задача кластеризации - задача обучения без учителя, в которой алгоритму требуется выделить (придумать) новый категориальный признак. 

![Screenshot 2022-10-26 at 03.47.15.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_03.47.15.png)

![Screenshot 2022-10-26 at 03.47.58.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_03.47.58.png)

Пример: разбиение песен по жанрам, но лень придумывать жанры песен

Внутренние меры - такие меры, которые используют для оценки само множество объектов и метки кластеров, которые вернула кластеризация и они не используют никакой внешней информации

![Screenshot 2022-10-26 at 03.54.36.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_03.54.36.png)

Мы хотим минимизировать среднее внутрикластерное расстояние и максимизировать среднее межкластерное расстояние. 

Внешние меры - можем использовать реальные метки классов, если изначальный набор данных, который мы кластаризуем был для задачи классификации, но на прямую меры для задач классификации мы использовать не можем, потому что метка кластера, которую мы придумываем, будет какой то новой категорией объекта, которую нельзя будет сравнивать с метками классов. Кроме того, число классов может отличаться от числа кластеров. 

Мы можем взять TP, FP, FN, TP но вычислять их иным способом. 

![Screenshot 2022-10-26 at 04.06.57.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_04.06.57.png)

(последний - TN)

![Screenshot 2022-10-26 at 04.08.02.png](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Screenshot_2022-10-26_at_04.08.02.png)

# 41. Графовые методы кластеризации

∙ Основная идея: будем работать с графом. Его вершины
являются объектами, а длины его рёбер равны расстояниям
между соответствующими объектами.
∙ Кластеры могут быть хорошо представлены в графическом
описании.

Алгоритм

1. Зафиксируем радиус R.
2. Удалим рёбра (u, v) : ρ(u, v) > R (все ребра, превышающие порог R)
3.  Посмотреть на компоненты связности графа. Эти самые компоненты связности образуют кластеры, т.е. кластеры соответствуют связанным компонентам.

Получение нужного числа кластеров:
∙ Нужное число кластеров можно получить бинарным поиском по R.

# 42. Иерархические методы кластеризации

**Иерархическая кластеризация** **— множество алгоритмов кластеризации, направленных на создание иерархии вложенных разбиений исходного множества объектов.

Иерархические алгоритмы кластеризации часто называют **алгоритмами таксономии**. 

Идея следующая: пусть будем строить **дендрограмму**
 — дерево иерархии кластеров, построенное по матрице мер близости между кластерами. В узлах дерева находятся подмножества объектов из обучающей выборки. При этом на каждом ярусе дерева множество объектов из всех узлов составляет исходное множество объектов. Объединение узлов между ярусами соответствует слиянию двух кластеров. При этом длина ребра соответствует расстоянию между кластерами.

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2012.png)

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2013.png)

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2014.png)

# 43. k-means. c-means

**k-means** - Итеративный алгоритм, основанный на минимизации суммарного квадратичного отклонения точек кластеров от центров этих кластеров;

Простой, но в то же время достаточно неточный метод кластеризации в классической реализации. Он разбивает множество элементов векторного пространства на заранее известное число кластеров k. Он стремится минимизировать среднеквадратичное отклонение на точках каждого кластера. Основная идея заключается в том, что на каждой итерации перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Алгоритм завершается, когда на какой-то итерации не происходит изменения кластеров.

Проблемы алгоритма k-means:

- **необходимо заранее знать количество кластеров**
- **алгоритм очень чувствителен к выбору начальных центров кластеров**
- не справляется с задачей, когда объект принадлежит к разным кластерам в равной степени или не принадлежит ни одному.

****с-means****

С последней проблемой k-means успешно справляется алгоритм с-means. Вместо однозначного ответа на вопрос к какому кластеру относится объект, он определяет вероятность того, что объект принадлежит к тому или иному кластеру.

---

**k-means** - итерационный алгоритм, который разбивает наборы на k частей. Центр масс у кластера (среднее внутрикластерное расстояние по каждому признаку) $C_j$ называется центроидом.

Это упрощение EM-алгоритма с сильной ассоциацией только с одним классом.

1. Выбрать k-точек (центроидов) из набора данных $\{c_i\}^k_{i=1}$.
2. Повторять
3. Для каждого x найти ближайший центроид n(x).

$C_i=\{x|n(x)=c_i\}$

1. Для каждого $C_i$ найти центральную точку и определить ее центроидом.
2. Пока центроиды не будут изменяться.

Есть и модификация: k-means++

Как предотвратить произвольно плохие локальные минимумы в k-средних? Делать то же самое, что и в k-средних, но выбирать новый центр i-го кластера с вероятностью, пропорциональной $||p-c_i||^2$.

# 44. Алгоритм DBSCAN

Основная идея метода заключается в том, что алгоритм разделит заданный набор точек в некотором пространстве на группы точек, которые лежат друг от друга на большом расстоянии. Объекты, которые лежат отдельно от скоплений с большой плотностью, будут помечены как шумовые.

На вход алгоритму подаётся набор точек, параметры ϵ (радиус окружности) и m (минимальное число точек в окрестности). Для выполнения кластеризации потребуется поделить точки на четыре вида: основные точки, прямо достижимые, достижимые и шумовые.

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2015.png)

Основная точка вместе со всеми достижимыми из нее точками формирует *кластер*. В кластер будут входить как основные, так и неосновные точки. Таким образом, каждый кластер содержит по меньшей мере одну основную точку.

Алгоритм начинается с произвольной точки из набора, которая еще не просматривалась. Для точки ищется ϵ-окрестность. Если она не содержит как минимум mm точек, то помечается как шумовая, иначе образуется кластер K, который включает все точки из окрестности. Если точка из окрестности уже является частью другого кластера C_j, то все точки данного кластера добавляются в кластер K. Затем выбирается и обрабатывается новая, не посещённая ранее точка, что ведёт к обнаружению следующего кластера или шума.

На выходе получаем разбиение на кластеры и шумовые объекты. Каждый из полученных кластеров C_j является непустым множеством точек и удовлетворяет двум условиям:

- Любые две точки в кластере попарно связаны (то есть найдется такая точка в кластере, из которой достижимы обе этих точки).
- Если точка достижима из какой-либо точки кластера, то она принадлежит кластеру.

DBSCAN находит практическое применение во многих реальных задачах, например, в маркетинге: необходимо предложить покупателю релевантный товар, который подойдет под его заказ. Выбрать такой товар можно, если посмотреть на похожие заказы других покупателей — в таком случае похожие заказы образуют кластер вещей, которые часто берут вместе. Похожим образом с помощью DBSCAN можно исследовать и находить общие интересы людей, делить их на социальные группы, моделировать поведение посетителей сайта. Алгоритм также может использоваться для [сегментации изображений](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B5%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9).

# 45. Уменьшение размерности; синтез признаков; выбор признаков; алгоритмы фильтрации

Под **уменьшением размерности** в машинном обучении подразумевается уменьшение числа признаков набора данных. Наличие в нем признаков избыточных, неинформативных или слабо информативных может понизить эффективность модели, а после такого преобразования она упрощается, и соответственно уменьшается размер набора данных в памяти и ускоряется работа алгоритмов ML на нем. Уменьшение размерности может быть осуществлено методами выбора признаков или выделения признаков.

Методы **выбора признаков** оставляют некоторое подмножество исходного набора признаков, избавляясь от признаков избыточных и слабо информативных (вторая группа включает в себя все остальные алгоритмы, даже где k > n). Основные преимущества этого класса алгоритмов:

- Уменьшение вероятности [переобучения](http://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5);
- Увеличение точности предсказания модели;
- Сокращение времени обучения;
- Увеличивается семантическое понимание модели.

Все методы выбора признаков можно разделить на 5 типов, которые отличаются алгоритмами выбора лишних признаков:

- фильтры - измеряют релевантность признаков на основе функции μ, и затем решают по правилу k, какие признаки оставить в результирующем множестве.
- **Оберточные методы -** находят подмножество искомых признаков последовательно, используя некоторый классификатор как источник оценки качества выбранных признаков, т.е. этот процесс является циклическим и продолжается до тех пор, пока не будут достигнуты заданные условия останова.
- ****Встроенные методы -**** похожи на оберточные методы, но для выбора признаков используется непосредственно структуру некоторого классификатора. В оберточных методах классификатор служит только для оценки работы на данном множестве признаков, тогда как встроенные методы используют какую-то информацию о признаках, которую классификаторы присваивают во время обучения.
- ****Правила обрезки -**** Для признаков, у которых найдено качество, можно выкинуть ненужное число признаков****.****
- **Гибридные методы** (комбинируют несколько разных методов выбора признаков, например, некоторое множество фильтров, а потом запускают оберточный или встроенный метод. Таким образом, гибридные методы сочетают в себе преимущества сразу нескольких методов, и на практике повышают эффективность выбора признаков) **Ансамблевые методы** (применяются больше для наборов данных с очень большим числом признаков. В данном подходе для начального множества признаков создается несколько подмножеств признаков, и эти группы каким-то образом объединяются, чтобы получить набор самых релевантных признаков. Это довольно гибкая группа методов, т.к. для нее можно применять различные способы выбора признаков и объединения их подмножеств).

**Фильтры** могут быть:

- Одномерные (англ. *univariate*) — функция μ определяет релевантность одного признака по отношению к выходным меткам. В таком случае обычно измеряют "качество" каждого признака и удаляют худшие;
- Многомерные (англ. *multivariate*) — функция μ определяет релевантность некоторого подмножества исходного множества признаков относительно выходных меток.

Распространенными вариантами для μ являются:

- Коэффициент ранговой корреляции Спирмена
- Information gain

Преимуществом группы фильтров является простота вычисления релевантности признаков в наборе данных, но недостатком в таком подходе является игнорирование возможных зависимостей между признаками.

# 46. Алгоритмы-обертки; встроенные методы выбора признаков

Алгоритмы-обертки - такие алгоритмы, которые используют классификатор или регрессор для оценки качества получаемого подмножества признаков и использует алгоритмы дискретной оптимизации для поиска оптимального подмножества признаков.

Существует несколько типов оберточных методов: детерминированные, которые изменяют множество признаков по определенному правилу, а также стохастические - сводят задачу выбора признаков к задаче оптимизации в пространстве бинарных векторов. 

Среди детерминированных алгоритмов самыми простыми являются:

- SFS (Sequential Forward Selection) — жадный алгоритм, который начинает с пустого множества признаков, на каждом шаге добавляя лучший из еще не выбранных признаков в результирующее множество;
- SBS (Sequential Backward Selection) — алгоритм обратный SFS, который начинает с изначального множества признаков, и удаляет по одному или несколько худших признаков на каждом шаге.

Среди стохастических:

- Поиск восхождения на холм
- Генетические алгоритмы

**Встроенные методы выбора признаков** - методы выбора признаков, при которых выбор осуществляется в процессе работы других алгоритмов (классификаторов и регрессоров).

Популярным оберточным методом является SVM-RFE (SVM-based Recursive Feature Elimination), который иногда также обозначается как **встроенный**. Этот метод использует как классификатор [SVM](http://neerc.ifmo.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D1%8B%D1%85_%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2_(SVM)) и работает итеративно: начиная с полного множества признаков обучает классификатор, ранжирует признаки по весам, которые им присвоил классификатор, убирает какое-то число признаков и повторяет процесс с оставшегося подмножества фичей, если не было достигнуто их требуемое количество. Таким образом, этот метод очень похож на встроенный, потому что непосредственно использует знание того, как устроен классификатор.

Одним из примеров встроенного метода является реализация на [случайном лесе](http://neerc.ifmo.ru/wiki/index.php?title=%D0%94%D0%B5%D1%80%D0%B5%D0%B2%D0%BE_%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D0%B9_%D0%B8_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D1%8B%D0%B9_%D0%BB%D0%B5%D1%81): каждому дереву на вход подаются случайное подмножество данных из датасета с каким-то случайным набор признаков, в процессе обучения каждое из деревьев решений производит "голосование" за релевантность его признаков, эти данные агрегируются, и на выходе получаются значения важности каждого признака набора данных. Дальнейший выбор нужных нам признаков уже зависит от выбранного критерия отбора.

Встроенные методы используют преимущества оберточных методов и являются более эффективными, при этом на отбор тратится меньше времени, уменьшается риск [переобучения](http://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%B5%D1%80%D0%B5%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5), но т.к. полученный набор признаков был отобран на основе знаний о классификаторе, то есть вероятность, что для другого классификатора это множество признаков уже не будет настолько же релевантным.

# 47. Алгоритм PCA

Бывает линейным и нелинейным. Линейный быстрее и более интерпретируемый, нелинейный находит более сложные признаки.

**PCA (метод главных компонент)** - наиболее известный метод для извлечения признаков. 

Метод осуществляет линейное отображение данных в пространство меньшей размерности таким образом, что дисперсия данных в малоразмерном представлении максимизируется. На практике строится матрица ковариации (а иногда корреляции) данных и вычисляются собственные вектора этой матрицы. Собственные вектора, соответствующие наибольшим собственным значениям (главные компоненты) теперь можно использовать для восстановления большей части дисперсии исходных данных. Более того, первые несколько собственных векторов часто можно интерпретировать в терминах крупномасштабного поведения системы. Исходное пространство (с размерностью, равной числу точек) редуцируется (с потерей данных, но надеждой, что остается наиболее важная дисперсия) до пространства, натянутого на несколько собственных векторов.

# 48. Алгоритм t-SNE

t-SNE (**Стохастическое вложение соседей)** — это алгоритм нелинейного снижения размерности, хорошо подходящий для визуализации. Каждый объект укладывается в пространство малой размерности таким образом, что похожим объектам будут соответствовать близко расположенные точки, и наоборот, непохожие объекты представляются далеко расположенными друг от друга точками.

1. Определим вероятность для точки “выбрать ближайшим соседом” другую точку в пространстве
2. Построим такие распределения для высокоразмерных и низкоразмерных представлений
3. Минимизируем расстояние между двумя распределениями

# 49. Автокодировщик

Автокодировщик - глубокая нейронная сеть, способная строить низкоразмерные представления данных за счет нелинейной трансформации.

Основная идея: заставим сеть предсказывать (восстанавливать) то, что подается ей на вход, ограничив возможность обучиться тривиальному преобразованию.

Два варианта реализации:

- структурный: между входными и выходными слоями должен быть слой меньшей размерности, т.н. бутылочное горлышко. Это недополненный автокодировщик.
- регуляризационный: добавим регуляризационную константу к выходам этого слоя, уменьшающим его размерность. Это разреженный кодировщик.

# 50. Алгоритм EM

**Алгоритм EM** (англ. *expectation-maximization*) — итеративный алгоритм поиска оценок максимума правдоподобия модели, в ситуации, когда она зависит от скрытых (ненаблюдаемых) переменных.

Алгоритм ищет параметры модели итеративно, каждая итерация состоит из двух шагов:

**E (Expectation)** шаг — поиск наиболее вероятных значений скрытых переменных.

**M (Maximization)** шаг — поиск наиболее вероятных значений параметров, для полученных на шаге E значений скрытых переменных.

EM алгоритм подходит для решения задач двух типов:

1. Задачи с неполными данными.
2. Задачи, в которых удобно вводить скрытые переменные для упрощения подсчета функции правдоподобия. Примером такой задачи может служить кластеризация.

### **Плюсы и минусы**

Плюсы:

- Сходится в большинтсве случаев.
- Наиболее гибкое решение.
- Существуют простые модификации, позволяющие уменьшить чуствительность алгоритма к шуму в данных.

Минусы:

- Чуствителен к начальному приближению. Могут быть ситуации, когда сойдемся к локальному экстремуму.
- Число компонент k является [гиперпараметром](http://neerc.ifmo.ru/wiki/index.php?title=%D0%9D%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B0_%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2).

# 51. Частичное обучение. Алгоритм S3VM

Частичное обучение - задача обучения с учителем, в которой только малая часть тренировочных данных содержит целевой признак.

Базовое решение:

- не использовать объекты, у которых пропущен целевой признак.
- не использовать целевой признак для обучения (задача обучения без учителя). Размеченные объекты можно использовать для тестирования.

Что мы имеем? Функция потерь содержит расстояние и до неразмеченных объектов.

Возникает проблема: использование hat loss приводит к невыпуклой оптимизации.

Подходы к решению:

- использовать алгоритмы невыпуклой оптимизации
- использовать сглаживание и градиентный спуск
- использовать верхнюю оценку и разбить на несколько задач выпуклой оптимизации

S3VM

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2016.png)

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2017.png)

# 52. Активное обучение. Метод uncertainty sampling

Активное обучение:

- есть доступ к большому числу объектов, но не у всех есть метки
- данные собираются быстро, а размечаются медленно и порционно, скорость обучения моделей происходит быстрее, чем разметка
- в активном обучении условия такие же, как в частичном обучении, но можно задавать Оракулу вопросы о значении меток
- требуется восстановить f: X→Y за наименьшее число обращений к Оракулу (найти стратегию обращений к Оракулу, оптимизирующую качество аппроксимации f).

**Выбор по степени неуверенности (англ. *uncertainty sampling*)** — метод отбора объектов из выборки, где самыми информативными объектами считаются те, на которых текущий алгоритм меньше всего уверен в верности классификации. Для этого необходимо задать меру неуверенности в классификации на каждом объекте.

Зафиксируем модель на некотором этапе обучения и обозначим за P(y|x) вероятность того, что объект x принадлежит классу y. Приведем основные меры неуверенности для текущей классификации:

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2018.png)

# 53. Сэмплирование; алгоритм SMOTE

**Сэмплирование** (англ. *data sampling*) — метод корректировки обучающей выборки с целью балансировки распределения классов в исходном наборе данных. Нужно отличать этот метод от [сэмплирования в активном обучении](http://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5#.D0.9C.D0.B5.D1.82.D0.BE.D0.B4.D1.8B_.D0.BE.D1.82.D0.B1.D0.BE.D1.80.D0.B0_.D0.BE.D0.B1.D1.8A.D0.B5.D0.BA.D1.82.D0.BE.D0.B2) для отбора кандидатов и от сэмплирования в статистике для создания подвыборки с сохранением распределения классов.

Неравномерное распределение может быть следующих типов:

- Недостаточное представление класса в *независимой* переменной;
- Недостаточное представление класса в *зависимой* переменной.

## Стратегии сэмплирования

- **Cубдискретизация** (англ. *under-sampling*) — удаление некоторого количества примеров мажоритарного класса.
- **Передискретизации** (англ. *over-sampling*) — увеличение количества примеров миноритарного класса.
- **Комбинирование** (англ. *сombining over- and under-sampling*) — последовательное применение субдискретизации и передискретизации.
- **Ансамбль сбалансированных наборов** (англ. *ensemble balanced sets*) — использование встроенных методов сэмплирования в процессе построения ансамблей классификаторов.

**Алгоритм SMOTE**

1. Случайно выбрать точку $a$
2. Выбрать $k$ ближайших точек из ее класса
3. Случайно выбрать одну из них, $b$
4. Случайно выбрать точку на отрезке $(a,b)$.
5. Добавить ее с той же меткой класса, что у и а

# 54. Обучение с первого взгляда; сиамская сеть

**Обучение с первого взгляда**

Сценарий:

- число классов может увеличиться
- в некоторых классах сравнительно мало объектов

Тогда можем прибегнуть к следующему:

**Обучение на одном примере** - это постановка, в которой алгоритм должен дообучиться классификации на новый класс, содержащий всего один объект.

**Обучение на нескольких примерах** - предполагает все то же, но с несколькими объектами.

**Сиамская сеть** - состоит из двух идентичных сетей, возвращающие векторные представления входов. Для обучения используется в таком случае triplet loss:

$L(a,p,n)=max(dist(a,p)-dist(a,n)+ \epsilon,0)$

Обучение: сеть обучается по батчам троек градиентным спуском.

Вывод: для каждого калсса хранится объект (центроид), с которыми сравнивается вход по косинуснуму расстоянию. Чтобы добавить класс, добавляется новый обхект в качестве центроида.

# 55. Аномалии; шумы

Аномалии (выбросы) - плохие объекты для построения модели

### **Виды выбросов**

На основе размерности изучаемого массива данных выбросы подразделяют на одномерные и многомерные.

**Одномерные выбросы**

Точка является выбросом только по одной из своих координат.

**Многомерные выбросы**

Точка является выбросом сразу по нескольким координатам.

Другой подход классификации выбросов — по их окружению.

**Точечные выбросы**

Единичные точки, выбивающиеся из общей картины. Точечные аномалии часто используются в системах контроля транзакций для выявления мошенничества, например, когда с украденной карты совершается крупная покупка.

**Контекстуальные выбросы**

Для того, чтобы определить, является ли точка выбросом необходим контекст. Например, в Петербурге +15 градусов Цельсия. Зимой такая температура является выбросом, а летом нет. 

**Коллективные выбросы**

Здесь выбросом является не точка, а группа точек. Примером таких выбросов могут служить, например, задержки поставок на фабрике. Одна задержка не является выбросом. Но если их много, значит это может стать проблемой.

### **Причины возникновения выбросов**

- Сбой работы оборудования;
- Человеческий фактор;
- Случайность;
- Уникальные явления;
- и др.

Шум – записи в наборе данных, не укладывающиеся в ту или иную концепцию [Классификации (Classification)](https://www.helenkapatsa.ru/shum/www.helenkapatsa.ru/klassifikatsiia/). Такие [Наблюдения (Observation)](https://www.helenkapatsa.ru/nabliudieniie/)
 вызваны человеческой ошибкой при создании [Датасета (Dataset)](https://www.helenkapatsa.ru/dataset/)
 или иными причинами. Зашумленный набор наносит ущерб всему [Пайплайну (Pipeline)](https://www.helenkapatsa.ru/paiplain/)
. Зашумленность измеряется как отношение чистых данных – сигнала к шуму. Существует много методов, используемых для искоренения шума.

Про шум подробнее: [https://www.helenkapatsa.ru/shum/](https://www.helenkapatsa.ru/shum/)

# 56. Задача генерации объектов

**Задача генерации объектов** — задача, связанная с машинным обучением, заключающаяся в создании новых правдоподобных объектов на основании заданной выборки. Полученные объекты могут быть использованы как для прикладных целей (в таком случае, это чаще всего изображения), так и для генерации объектов для тренировочной выборки, когда размечать настоящие данные — долго и дорого, или их нужно анонимизировать. В зависимости от того, для какой из этих целей используется генерация объектов, постановка задачи и методы её решения несколько отличаются. Для достижения данной цели обычно используются [порождающие модели](http://neerc.ifmo.ru/wiki/index.php?title=%D0%9F%D0%BE%D1%80%D0%BE%D0%B6%D0%B4%D0%B0%D1%8E%D1%89%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8) (т.е. используется генератор - сеть, которая генерирует объекты, и дискриминатор - сеть, которая будет будет отличать сгенерированные объекты от настоящих).

Подробнее тут: [http://neerc.ifmo.ru/wiki/index.php?title=Генерация_объектов](http://neerc.ifmo.ru/wiki/index.php?title=%D0%93%D0%B5%D0%BD%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D0%BE%D0%B1%D1%8A%D0%B5%D0%BA%D1%82%D0%BE%D0%B2)

# 57. GANs

Генеративно-состязательная сеть (GAN): производная по объекту используется как производная по выходу генератора, который эти объекты генерирует.

Схема выглядит примерно вот так:

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2019.png)

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2020.png)

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2021.png)

# 58. CGANs

Те же генеративно-состязательные модели (GANs), но с модификацией:

- идея состоит в том, чтобы добавить несколько меток, чтобы дискриминатор мог работать как классификатор по отношению к некоторым меткам.
- в этом случае у нас разное распределение для каждого класса
- тогда у нас меняется целевая функция

![Untitled](%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5%20%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B5%D0%BE%D1%80%20%D0%BC%D0%B8%D0%BD%200697fd95ac7b4e41b007dd2eb43529ba/Untitled%2022.png)

# 59. Вариационный автокодировщик

**Вариационный автокодировщик** — [автокодировщик](http://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA)
 (генеративная модель, которая учится отображать объекты в заданное скрытое пространство (и обратно)) основанный на вариационном выводе.

При попытке использования обыкновенного автокодировщика для генерации новых объектов (желательно из того же априорного распределения, что и датасет) возникает следующая проблема. Случайной величиной с каким распределением проинициализировать скрытые векторы, для того, чтобы картинка, после применения декодера, стала похожа на картинки из датасета, но при этом не совпадала ни с одной из них? Ответ на этот вопрос не ясен, в связи с тем, что обыкновенный автокодировщик не может ничего утверждать про распределение скрытого вектора и даже про его область определения. В частности, область определения может быть даже дискретной.

Вариационный автокодировщик в свою очередь предлагает пользователю самому определить распределение скрытого вектора.

Благодаря тому, что пользователь сам устанавливает нужное распределение скрытого вектора, вариационный кодировщик хорошо подходит для генерации новых объектов (например, картинок). Для этого достаточно разыграть скрытый вектор согласно его распределению и подать на вход декодера. Получится объект из того же распределения, что и датасет.

Подробнее тут: [http://neerc.ifmo.ru/wiki/index.php?title=Вариационный_автокодировщик](http://neerc.ifmo.ru/wiki/index.php?title=%D0%92%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B0%D0%B2%D1%82%D0%BE%D0%BA%D0%BE%D0%B4%D0%B8%D1%80%D0%BE%D0%B2%D1%89%D0%B8%D0%BA)